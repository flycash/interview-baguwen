# 你是否了解 Kafka

分析： 如果只是宽泛地谈 Kafka，那么回答的点就要围绕 Kafka 的几个组成来。这个部分不必谈及“为什么 Kafka 高性能” “为什么 Kafka 高可用”等问题。因为按照一般的惯例，接下来就会聊这个话题。总跳回答的思路就是介绍一下 Kafka 的基本原理，几个主要概念。后面详细的内容，等后面面试官来提问。

![Kafka知识点](img/kafka_available_performance.png)

答：Kafka 是一个基于发布订阅模式的消息队列中间件。它由 Producer, Consumer, Broker 和 Partition 几个组成。

Kafka 里面的每一个消息都属于一个主题，每一个主题都有多个 Partition。Partition 又可以使用主从复制模式，即 Partition 之间组成主从模式。这些 Partition 均匀分布在 Broker 上，以保证高可用。（这里点到了高可用，引导面试官探讨 Kafka 高可用）。每一个 Partition 内消息是有序的，即分区顺序性。（这一句是为了引出后面如何保证消息有序性）

Producer 依据负载均衡设置，将消息发送到 Topic 的特定 Partition 下；（后面面试官可能会问负载均衡策略）

Consumer 之间组成了 Consumer Group，可以有多个 Consumer Group 消费同一个 Topic，互相之间不会有影响。Kafka 强制要求每个 Partition 只能有一个 Consumer，并且 Consumer 采取拉模式，消费完一批消息之后再拉取一批（尝试引出来后面的拉模型的讨论）；

一个 Kafka 集群由多个 Broker 组成，每个 Broker 上存放着不同 Topic 的 Partition；

![Topic，Broker 和 Partition](https://pic2.zhimg.com/80/v2-17a2d36445a764081b45e012397291bd_720w.jpg)

## 扩展点

### Kafka 的高性能是如何保证的？

分析：必考题。高性能的影响因素有很多，但是常考的就是顺序写 + 零拷贝。在这个问题之下，我们只需要罗列出来各个点，但是不做深入解释。在罗列完之后，我们重点对其中某些点做详细说明，一般我建议用零拷贝做深入阐释。当然，最好是记得所有的点，包括它们的细节，不过这样一回答，没有三五分钟答不完。

答：Kafka 高性能依赖于非常多的手段：
1. 零拷贝。在 Linux 上 Kafka 使用了两种手段，mmap (内存映射，一般我都记成妈卖批，哈哈哈) 和 sendfile，前者用于解决 Producer 写入数据，后者用于 Consumer 读取数据；
2. 顺序写：Kafka 的数据，可以看做是 AOF （append only file），它只允许追加数据，而不允许修改已有的数据。（后面是亮点）该手段也在数据库如 MySQL，Redis上很常见，这也是为什么我们一般说 Kafka 用机械硬盘就可以了。有人做过实验（的确有，你们可以找找，我已经找不到链接了），机械磁盘 Kafka 和 SSD Kafka 在性能上差距不大；
3. Page Cache：Kafka 允许落盘的时候，是写到 Page Cache的时候就返回，还是一定要刷新到磁盘（主要就是mmap之后要不要强制刷新磁盘），类似的机制在 MySQL, Redis上也是常见，（简要评价一下两种方式的区别）如果写到 Page Cache 就返回，那么会存在数据丢失的可能。
4. 批量操作：包括 Producer 批量发送，也包括 Broker 批量落盘。批量能够放大顺序写的优势，比如说 Producer 还没攒够一批数据发送就宕机，就会导致数据丢失；
5. 数据压缩：Kafka 提供了数据压缩选项，采用数据压缩能减少数据传输量，提高效率；
6. 日志分段存储：Kafka 将日志分成不同的段，只有最新的段可以写，别的段都只能读。同时为每一个段保存了偏移量索引文件和时间戳索引文件，采用二分法查找数据，效率极高。同时 Kafka 会确保索引文件能够全部装入内存，以避免读取索引引发磁盘 IO。（这里有一点很有意思，就是在 MySQL 上，我们也会尽量说把索引大小控制住，能够在内存装下，在讨论数据库磁盘 IO 的时候，我们很少会计算索引无法装入内存引发的磁盘 IO，而是只计算读取数据的磁盘 IO）

（批量操作+压缩的亮点）批量发送和数据压缩，在处理大数据的中间件中比较常见。比如说分布式追踪系统 CAT 和 skywalking 都有类似的技术。代价就是存在数据丢失的风险；
（数据压缩的亮点）数据压缩虽然能够减少数据传输，但是会消耗更过 CPU。不过在 IO 密集型的应用里面，这不会有什么问题；

（下面是零拷贝详解）
一般的数据从网络到磁盘，或者从磁盘到网络，都需要经过四次拷贝。比如说磁盘到网络，要经过：

![四次拷贝](https://miro.medium.com/max/840/0*Q6eoQ-19bq-qkm_Y)

1. 磁盘到内核缓冲区
2. 内核缓冲区到应用缓冲区
3. 应用缓冲区到内核缓冲区
4. 内核缓冲区到网络缓冲

零拷贝则是去掉了第二和第三。（之所以叫零拷贝，并不是说完全没有拷贝，而是指没有CPU参与的拷贝，DMA的还在）。

![零拷贝](https://miro.medium.com/max/700/0*es45Nv-ea2WDtI0n)

(这一段可选，因为比较冷僻)如果在 Linux 高版本下，而且支持 DMA gather copy，那么内核缓冲区到

![零拷贝](https://miro.medium.com/max/700/0*XJNUTI5QoiCzSbxE)

Kafka 利用了两项零拷贝技术，mmap 和 sendfile。前者是用于解决网络数据落盘的，Kafka 直接利用内存映射，完成了“写入操作”，对于 Kafka 来说，完成了网络缓冲区到磁盘缓冲区的“写入”，之后强制调用`flush`或者等操作系统（有参数控制）。（继续补充细节，如果自己是JAVA开发并且记得的话）Java 提供了`FileChannel`和`MappedByteBuffer`两项技术来实现 mmap。

`sendfile`是另外一种零拷贝实现，主要解决磁盘到网络的数据传输。操作系统读取磁盘数据到内存缓冲，直接丢过去`socket buffer`，而后发送出去。很多中间件，例如 `Nignx`, `tomcat` 都采用了类似的技术。

关键字：零拷贝，顺序写，缓冲区，批量，压缩，分段存储


#### 类似问题
- 什么是零拷贝
- 为什么顺序写那么快？
- Kafka 为什么那么快？
- 

#### 如何引导
- 讨论到了零拷贝技术
- 讨论到了顺序写技术

### Kafka 的 ISR 是如何工作的？

分析：考察的是 Partition 同步问题。回答这个问题的时候，要清晰解释清楚，一个 Producer 写入一条消息，到 Partition 同步完成的步骤。亮点在于说清楚，这些步骤如果出现问题会导致什么结果。这里还牵涉到三个基本概念，ISR，HW，LEO。容易混淆的两个时间点，一个是消息写入成功，一个是消息同步成功。这是两个不同的东西。同样，另外一个容易混淆的是，ISR 里面的分区数据和主分区还是有差别的，也就是说，我们认为从分区与主分区保持同步，并不是严格的。

答：ISR 是分区同步的概念。Kafka 为每个主分区维护了一个 ISR，处于 ISR 的分区意味着与主分区保持了同步（所以主分区也在 ISR 里面）。

当 Producer 写入消息的时候，需要等 ISR 里面分区的确认，当 ISR 确认之后，就被认为消息已经提交成功了。ISR 里面的分区会定时从主分区里面拉取数据，如果长时间未拉取，或者数据落后太多，分区会被移出 ISR。ISR 里面分区已经同步的偏移量被称为 LEO（Log End Offset），最小的 LEO 称为 HW（高水位，high water，这个用木桶来比喻就很生动，ISR 里面的分区已同步消息就是木板，高水位就取决于最短的那个木板，也就是同步最落后的），也就是消费者可以消费的最新消息。

![LEO 和 HW](https://img-blog.csdnimg.cn/20200706235345430.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FqaWFueWluZ3hpYW9xaW5naGFu,size_16,color_FFFFFF,t_70)

当主分区挂掉的时候，会从 ISR 里面选举一个新的主分区出来。

（下面我们进一步解释一下 Producer 写入消息）
我们在 Producer 里面可以控制 ACK 机制。Producer 可以配置成三种：
1. Producer 发出去就算成功；
2. Producer 发出去，主分区写入本地磁盘就算成功；
3. Producer 发出去，ISR 所有的分区都写入磁盘，就算成功；

其性能依次下降，但是可靠性依次上升。

（如果记得，可以补上这个说明）因为 ISR 里面包含了主分区，也就是说，如果整个 ISR 只有主分区，那么全部写入就退化为主分区写入。所以在可靠性要求非常高的情况下，我们要求 ISR 中分区不能少于三个。该参数可以在 Broker 中配置（min.insync.replicas）

（回答到这里，我们基本上就说清楚了 ISR 的基本机制。下面我们横向对比一下 ISR 机制与别的主从同步机制。很明显的，就是 Producer 这种发送策略，是否等待同步完成，在很多中间件上都能看到，随便挑一个出来就可以。我这里总结一下：

ISR 的同步机制和其它中间件机制也是类似的，在涉及主从同步的时候都要在性能和可靠性之间做取舍。通常的选项都是：
1. 主写入就认为成功
2. 主写入，至少一个从写入就认为成功；
3. 主写入，大部分从库写入就认为成功（一般“大部分”是可以配置的，从这个意义上来说，2和3可以合并为一点）；
4. 主写入，所有从库写入就认为成功；

而“写入”也会有不同语义：
1. 中间件写到日志缓存就认为写入了；
2. 中间件写入到系统缓存（page cache）就认为写入了；
3. 中间件强制刷新到磁盘（发起了 fsync）就认为写入了；

都是性能到可靠性的取舍。）

（在面试的时候，可以考虑回答完 ISR 之后，将上面的总结说出来，可以借用 MySQL，Redis, ZK 来说明，这算是一般规律）


#### 类似问题
- Kafka GC 时间过长会导致什么问题？可能导致分区被踢出去 ISR。
- Kafka 是如何保证可靠性的？（除了 ISR 以外，还要强调一下 Partition 是分布在不同 Broker 上，以避免 Broker 宕机导致 Topic 不可用
- 如何提高 Kafka 的可靠性
- 如何提高 Kafka 吞吐量？可靠性和吞吐量在这里就是互斥的，调整参数只能提高一个，降低另外一个。

### 什么时候分区会被移出 ISR？

分析：考察 ISR 的特点，要理解 Kafka 如何维护 ISR 的。其实就两个参数控制，一个是落后多少消息，一个是多久没同步。比较有亮点的是能够清楚答出是哪两个参数，另外一个刷亮点的机会，就是说清楚它们过大过小都会有什么影响。

答案：当分区触发两个条件中的任何一个时，都会被移除出 ISR。
1. 消息落后太多，这个是参数`replica.lag.max.messages`。
2. 分区长时间没有发起`fetch`请求，由参数`replica.lag.time.max.ms`控制。

（刷亮点，点出影响因素，后面面试官跟你探讨这些因素怎么影响的）基本上，除非是新的 Broker，否则几乎都是由网络、磁盘IO和GC引起的，大多数情况下，是负载过高导致的。

（点出过大过小的影响）这两个参数，过小会倒是 ISR 频繁变化，过大会导致可靠性降低，存在数据丢失的风险。

（如果你知道你们公司的配置）我们公司的配置是 XXX 和 XXX。

关键字：落后多少消息，多久没同步

#### 如何引导
- 谈到 Kafka 可靠性可用性

### Kafka 的负载均衡策略有哪些？

分析：一般考察的是 Producer 怎么把消息分到对应的 Partition 上。理论上来说就是两种，一个是轮询，一个是 Hash 取余。这取决于 Key 是否为 Null。但是我们可以结合实际中的一些现实场景，来做一些扩展说明。特别是 Hash 取余。这种问题，列举有什么策略一类的面试题，其实单纯列出来，只能说是合格，要想回答好，就需要针对性地结合自己的经历，重点分析某些策略的优劣。所以我们的回答会先简单介绍有哪些策略，后面会重点落在 Hash 取余上，着重分析 Hash Key 对负载均衡的问题。

最后我们将话题引到 Partition 负载均衡与消费者负载均衡不匹配的问题上。它是指，我们的消息的确分布均匀了，但是处理不同的消息可能有快有慢，在极端情况下，可能处理慢的消息都在特定的 Partition 上，因此导致某个消费者负载奇高，而其余的消费者却没有什么负载。

答案：一般来说有两种，一种是轮询，即 Producer 轮流挑选不同的 Partition；另外一种是 Hash 取余，这要求我们提供 Key。
（接下来，我们讨论 Key 的选择对 Partition 负载的影响，主要是为了体现自己用 Kafka 解决不同问题的思路）

Key 的选取，大原则上是采用业务特征 ID，或者业务特征的某些字段拼接而成。比如说，我们可以考虑按照用 Order ID（可以替换成自己项目里面的某些业务的ID）作为 Key，这意味某个订单的消息肯定落在特定的某个 Partition 上，这就保证了针对该订单的消息是有序的（这里面间接提到了有序性的问题，体现了自己对于 Partition 的理解）。

（说一下 Hash 策略的风险）但是 Hash 策略下，如果 Key 设置不当，可能会导致某些 Partition 承载了大多数的流量。比如说按照商家 ID 来作为 Key，那么可能某些热点商家，大卖家，其消息就集中在某个 Partition 上，导致负载不均衡。

（我们升华一下这个问题，就是这些负载策略实际上都只考虑 Partition 的负载，而没有考虑 Consumer 的负载，为了进一步凸显自己对负载均衡的理解）
无论是轮询，还是 Hash，都无法解决一个问题：它们没有考虑 Consumer 的负载。例如，我们可以用 Hash 策略均匀分布了消息，但是可能某些消息消费得慢，有些消息消费得快。假如说非常不幸我们消费得慢的消息都落在某个 Partition，那么该 Partition 的消费者和别的消费者比起来，消费起来就很慢，带来很大的延迟，甚至出现消息堆积。

关键字：轮询，Hash，Key 的选取

#### 类似的问题
- 如何选取 Hash Key
- 你们是如何设置 Producer 推送消息到哪个 Partition 的？

#### 如何引导
- 在介绍 Kafka 的时候
- 讨论到 Hash Key 选择的时候。其实不仅仅是 Kafka，所有基于 Hash 的负载均衡算法，都会有类似的问题。所谓的 Hash 冲突，也就是这个问题。
- 聊到了消息有序性的时候

### 为什么 Kafka 的从 Partition 不能读取？

分析：考察 Kafka 消费者拉取消息的特点。这个问题的背景是，一般的主从模式，从服务器都可以提供读服务，但是 Kafka 的从 Partition 是不能提供读服务的。所以这也是一个违背一般规律的问题。我们回答的点就要从 Kafka 本身消息存储和消费者消费特点两方面回答。为了方便记忆，以及清楚解释这个问题，我们可以对比 MySQL 的主从模式，假设 Kafka 允许读从 Partition 的数据，会发生什么。

答：首先是 Kafka 自身的限制，即 Kafka 强制要求一个 Partition 只能有一个 Consumer，因此 Consumer 天然只需要消费主 Partition 就可以。

那么假如说 Kafka 放开这种限制，比如说有多个 Consumer，分别从主 Partition 和从 Partition 上读取数据，那么会出现一个问题：即偏移量如何同步的问题。例如一个 Consumer 从 Partition A 读取了 0- 100 的消息，那么另外一个 Consumer 从 Partition B 上读取，就只能读取 100 之后的数据。那么 Kafka 就需要在不同的 Partition 之间协调这个已读取偏移量。而这是分布式一致性的问题，难以解决。

MySQL 的主从模式比起来，并没有这种问题，即 MySQL 不需要进行类似偏移量的协商。

而从另外一个角度来说，Kafka 的读取压力是远小于 MySQL 的，毕竟一个 Topic，是不会有特别多的消费者的。并且 Kafka 也不需要支持复杂查询，所以完全没必要读取从 Partition 的数据。

关键字：偏移量

### 为什么 Kafka 在消费者端采用了拉（PULL）模型？
分析：考察拉模型的特点。回答的关键点在于，对比拉模型和推模型，在 MQ 这种场景下的优缺点。加分点在于明确指出什么 MQ 使用了什么模型。

答：采用拉模型的核心原因在于，消费者的消费速率不同。在拉模型之下，消费者自己消费完毕就自己再去拉去一批，那么这种速率是由消费者自己控制的，所需要的控制信息也是由消费者自己保存的。而采用推模型，就意味着中间件要和消费者就速率问题进行协商，否则容易导致要么推送过快，要么推送过慢的问题。

推模型的一个极大的好处是避免竞争，例如在多个消费者拉同一主题的消息的时候，就需要保证，不同消费者不会引起并发问题。而 Kafka 不会有类似的问题，因为 Kafka 限制了一个 Partition 只能有一个消费者，所以拉模型反而更加合适。

关键字：谁控制，并发竞争

### 分区过多会引起什么问题？

分析：这应该属于大厂题，因为一般的公司是不会遇到这种问题的。那么分区过多会引起什么问题，要从 Producer、Consumer 和 Broker 三者考虑。注意这里说的分区过多，一般都是指主分区本身就很多，而不是指我一个主分区有一千个从分区。后者，要从 ISR 的角度去分析。不过基本上不会面这个问题，面到了就怼回去，谁家的主分区会有一千个从分区。

答：对于 Producer 来说，它采用的是批量发送的机制，那么分区数量多的话，就需要消耗大量的内存来维护这些缓存的消息。同时，也增大了数据丢失的风险。

对于 Consumer 来说，分区数量多意味着要么部署非常多的实例，要么开启非常多的线程，无论是哪一种方案，都是开销巨大。

对于 Broker 来说，分区特别多而对应的 Broker 数量又不足的话，那么意味着一个 Broker 上分布着大量的分区，那么一次宕机就会引起 Kafka 延时猛增。同时，每一个分区都要求 Broker 开启三个句柄，那么会引起 Broker 上的文件句柄被急速消耗，可能导致程序崩溃。还要考虑到，Kafka 虽然采用了顺序写，但是这是指在一个分区内部顺序写，在多个分区之间，是无法做到顺序写的。

（注意，对于 Broker 来说，如果你的集群规模非常大，以至于虽然有一万个分区，但是每个 Broker 上只有寥寥几个分区，那么分区数量对 Broker 来说是没影响的。我们这里的讨论，都是建立在我一个 Broker 上放了很多分区的基础上）

（分区数量和性能的关系类似一个二次函数，随着分区增长会慢慢变好，但是到达一个临界点之后，就会开始衰退）
#### 类似问题
- 分区数量是不是越多越好？显然不是；
- 分区数量越多，是不是吞吐量越高？显然不是；
- 能不能通过增加分区数量来提高 Kafka 性能？注意，这个是可以的，但是要注意把握度，就是不能无限增加；
- Topic 过多会引起什么问题？其实差不多是同一个问题，Topic 多意味着分区多，而且通常伴随的是每个 Topic 的数据量都不大；

### 如何解决 Topic 的分区数量过多的问题？

分析：这个问题其实挺无解的。因为如果你确实有那么多消息需要消费，或者说写入压力很大的话，你就需要那么多分区。所以你很难说我削减分区。不过有一些措施能够缓解这个问题。

答：增加 Broker，确保 Broker 上不会存在很多的分区。这可以避免 Broker 上文件句柄数量过多，顺序写退化为随机写，以及宕机影响范围太大的问题。

其次可以考虑拆分 Topic 并且部署到不同的集群。（这里要注意，Topic 如果拆了但是没有增加 Broker，也没有部署额外的 Kafka 集群，那么其实还是没啥用）

当然，如果分区的写入负载其实并不大，那么可以考虑削减分区的。（尝试引出削减分区的话题，这是一个鱼钩，因为kafka本身不支持削减分区）

#### 类似问题
- 如何解决 Topic 太多的问题？这个问题稍微有点不同，我们考虑的就不是拆分 Topic 而是合并 Topic了。增加 Broker 有点效果，但是没有分区数量多那么有效。核心就在于, Topic 多伴随的都是每个 Topic 数据不多。

#### 如何引导
- 聊到了分区数量是不是越多越好

### 如何确定合适的分区数量？

分析：典型的计算容量题。所不同的是，分区数量会影响两端，因此要同时考虑 Producer 的效率和 Consumer 的效率。

答：使用 Kafka 提供的压测工具来测试。一般来说，我们对于某个特定的 Topic，其消息大小是能够从业务上推断出来的，也就是我们不存在说一个 Topic，某些消息特别长，某些消息特别短。大部分的消息长度都在相差不多的范围内。

因此我们可以控制写入一个分区的 TPS，观察同步延时和消息是否积压（消费端的消费数据，例如99线等也可以）。

#### 类似问题
- 如何确定消费者数量？要注意，消费者最多最多就是和分区数量一样，其它就是压测了。

#### 如何引导
- 聊到了分区数量过多的问题

### 如何保证消息有序性？方案有什么缺点？

分析：考察分区内部有序的特点。消息被投递到某个分区里面，是有序的，但是分区之间是没有顺序的。回答这道题，还要回答出来一个要点，即这并不意味着我们只能使用一个分区，而是可以考虑在发消息的时候主动指定分区，确保业务上要求顺序的消息都被投递到同一个分区中。

答：Kafka 要做到消息有序，只需要将消息都投递到同一个分区里面。因为 Kafka 的设计确保了一个分区内部的消息是有序的。但是，这并不是说，我们只能拥有一个分区，而是我们可以从业务上，将相关的消息都扔到了一个分区。例如按照用户 ID 来选择分区，确保用户相关的某些消息都在同一个分区内部。（点出缺点）类似的方案都要注意分区负载，例如热点用户产生了大量的消息，都被积压在该分区。

#### 类似问题
- Topic 为了保证消息有序性，我们会考虑只使用一个 Partition，你有什么改进方案？

### Kafka能不能重复消费？

分析：这个问题，其实不是指我们之前提到的，消费者如何避免重复消费中的那种因为超时引起的重复消费。面试官想问的是，我能不能主动重复消费。比如说，我程序有BUG，消费的时候出错了。等我修复完 BUG 之后，我打算重新消费一遍，有没有办法做到。所以准确来说是，消费者能不能消费历史上的消息。这里刷亮点的在于点出，消息保存时间，因为超过消息保存时间，就真找不着了。

答：能。Kafka 的分区用 offset 来记录消费者消费到哪里了。因此我们可以考虑指定 offset 来消费，比如指定一个很久之前的 offset。

一些场景之下，我们会更加倾向于指定时间节点，那么可以先根据时间戳找到 offset，然后再从 offset 消费。

不过要注意的是，有些时候，这些消息可能已经被归档（删除——一般都不会直接删除，而是丢到一个别的地方放起来，以防万一）了，那么这一类的消息，就确实是没法子重复消费了。

### Rebalance 发生时机
分析：考察 Rebalance 的基本特性。Rebalance 本质就是给消费组的消费者分配任务的过程。记住这个本质之后，那么 rebalance 的过程触发时机，就是 Topic、分区和消费者三个人的事情了。举个例子，就好比分苹果，无论是苹果数量，还是小朋友数量发生了变化，你都要重新来一遍。问这个问题，基本上是为了引出 rebalance 的过程，以及 rebalance 造成的影响。

答：
1. Topic 或者分区的数量变化（苹果数量变化，例如增加新的分区）
2. 消费者数量变化（加入或者退出）。这个又可以细分为两个：一个是消费超时（max.poll.interval.ms），一个是心跳超时（session.timeout.ms）

类似问题
- 什么时候会 Rebalance？
- 消费者加入或者退出会有啥影响？
- 扩容（指增加分区）会有什么影响？这两个都是引起 rebalance

### rebalance 的过程
分析：典型的过程题目。一般来说，结合具体的场景来回答步骤，容易记忆也容易理解。这里我们可以围绕着因为消费者变化引起的 rebalance 来回答。实际上，不同原因引起的 rebalance 过程是有一些差异的，不过这些差异不涉及根本，所以没必要在这里纠结。如果能够根据不同情况来回答步骤，那自然是好的。这里就是简化一下。

答：以新的消费者加入为例，这个步骤可以分成以下几步：
1. 新的消费者向协调者上报自己的订阅信息；
2. 协调者强制别的消费者发起一轮 rebalance，上报自己的订阅信息；
3. 协调者从消费者中挑选一个 leader，注意这里是挑选了消费者中的 leader；
4. 协调者将订阅信息发给 leader，让 leader 来制作分配方案；
5. leader 上报自己的方案；
6. 协调者同步方案给别的消费者

（更加简单的记忆方式是：挑选 leader -> leader 出方案 -> 同步方案，就很像一堆同事说我来搞负责解决这个问题，然后老板挑了一个卷王，说你出个方案，老板看了方案很满意，交代其它同事说按照这个方案执行)

### rebalance 有啥影响

分析：结合前面的 rebalance 的过程，也可以看到，rebalance 对消费者的影响是最大的，因为在 rebalance 的过程中，都不能消费。前面的一大堆的 rebalance 问题，实际上对于一个增删改查工程师来说，就是为了引出这个话题。

答：
1. 重复消费：如果在消费者已经消费了，但是还没提交，这个时候发生了 rebalance，那么别的消费者可能会再一次消费；
2. 影响性能：rebalance 的过程，一般是在几十毫秒到上百毫秒。这个过程会导致集群处于一种不稳定状态中，影响消费者的吞吐量；

#### 如何引导
- 在前面聊到过程，就可以主动聊有什么影响

### 如何避免 rebalance？
分析：前面我们说过，要么是 Topic 或者分区变化引起，要么是消费者变化引起，这两个都会导致 rebalance。所以如何避免，就是如何避免出现这两种变化。

答：首先，Topic 或者分区变化，引起 rebalance 是无法避免的，因为一般都是因为业务变化引起的。比如说，随着流量增加，我们要增加分区。

能够避免的就是防止消费者出现消费超时或者心跳超时。消费超时可以增大`max.poll.interval.ms` 参数，避免被协调者踢掉。或者优化消费逻辑，使得消费者能够快速消费，拉取下一批消息。

而心跳超时，也可以通过增大`session.timeout.ms`来缓解。

（可以进一步分析这两个参数增大的弊端）
但是这两个参数增大，都可能导致，消费者真的出了问题，但是协调者却迟迟没有感知到的问题。

#### 如何引导
- 聊到 rebalance 的影响

### 为什么 Kafka 不支持减少分区？

分析：Kafka 增加分区是可以的，但是减少分区是不能的。这个问题，只要想一下，减少分区要怎么实现，就能得出结论。它的核心难点是，减少的这个分区上的数据怎么处理？比如说，能不能分给别的分区，要分怎么分？对应的消费者怎么处理？在回答了为什么不能减少之后，给出一个可能的解决方案。

答：主要还是在于，难以处理分区上的数据。假如说，我们要支持 Kafka 支持减少分区，那么我们就要考虑第一个问题，这个分区上的数据，该怎么办？大多数情况下，我们不能直接丢掉，那么只能考虑重新分配给其它的分区。于是就涉及到，如何分配，以及对其余分区的影响的问题了。

总体来说，减少分区的复杂度，远比增加分区的复杂度大，但是收益是小的。一方面，有别的手段来解决类似的问题，另一方面，大多数的场景，都是增加分区，而不是减少分区。

假如我们要实现类似的功能，可以考虑两种方案：
1. 创建一个完全一样的 Topic，然后分区数量少一点，等老的 Topic 消费完就直接下线，只留下这个新的 Topic；
2. 考虑在写入分区的时候，不再写入特定的分区，可以通过业务来控制，也可以通过负载均衡机制来控制；其缺点是，这个没用的分区会长期存在，并没有在事实上删除它；


## References
[图解Kafka高可用机制](https://zhuanlan.zhihu.com/p/56440807)

[Kafka高性能原理](https://zhuanlan.zhihu.com/p/105509080)

[Why Kafka is fast](https://preparingforcodinginterview.wordpress.com/2019/10/04/kafka-3-why-is-kafka-so-fast/)